= SCDF Tensorflow Demos

== Perquisites
* Install Docker: https://www.docker.com/community-edition

NOTE: Make sure to increase the memory limits to at least 4G

== Quick Start

* Checkout the SCDF environment:
[source,bash]
----
git clone https://github.com/tzolov/scdf-tensorflow-demos.git
cd ./scdf-tensorflow-demos
DATAFLOW_VERSION=latest docker-compose up
----

NOTE: Remove any existing `dataflow-server` containers `docker rm dataflow-server`

* Open the preconfigured SCDF UI: http://localhost:9393/dashboard

* (Optional) Login into the `dataflow-server` container:
[source,bash]
----
docker exec -it dataflow-server /bin/sh
----

== SCDF Tensorflow Demos

=== Image Recognition

A https://github.com/spring-cloud-stream-app-starters/tensorflow/blob/master/spring-cloud-starter-stream-processor-image-recognition/README.adoc[Image Recognition Processor] that uses an Inception model to classify in real-time images into different categories (e.g. labels).
Model implements a deep Convolutional Neural Network that can achieve reasonable performance on hard visual recognition tasks - matching or exceeding human performance in some domains like image recognition.

[source,bash]
----
inception-stream=in: file --directory='/input/image-recognition' | image-recognition --model-fetch=output --model='http://dl.bintray.com/big-data/generic/tensorflow_inception_graph.pb' --labels='http://dl.bintray.com/big-data/generic/imagenet_comp_graph_label_strings.txt' --response-size=3 --tensorflow.mode=header --draw-labels=true | out: file --directory='/output/image-recognition' --mode=REPLACE --name-expression='headers[file_name]'

labels-metadata=:inception-stream.image-recognition > transform --expression="{#jsonPath(headers[result].toString(),'$.labels')}" | log
----

=== Object Detection

The https://github.com/spring-cloud-stream-app-starters/tensorflow/tree/master/spring-cloud-starter-stream-processor-object-detection[Object Detection processor]
provides out-of-the-box support for the TensorFlow Object Detection API. It allows for real-time localization and identification of multiple objects in a single image or image stream. The Object Detection processor uses one of the pre-trained object detection models and corresponding object labels.


[source,bash]
----
object-detection-stream=file --directory='/input/object-detection' | object-detection2 --tensorflow.mode=header --tensorflow.model='http://dl.bintray.com/big-data/generic/faster_rcnn_resnet101_coco_2018_01_28_frozen_inference_graph.pb' --tensorflow.model-fetch='detection_scores,detection_classes,detection_boxes' --tensorflow.object.detection.labels='http://dl.bintray.com/big-data/generic/mscoco_label_map.pbtxt' --draw-bounding-box=true | out: file --mode=REPLACE --directory='/output/object-detection' --binary=true --name-expression='headers[file_name]'
----

=== Pose Estimation (new)



[source,bash]
----
poses= in: file --directory='/input/pose-estimation'  | pose-estimation --mode=header --tensorflow.model='file:/apps/model/thin.pb' --tensorflow.model-fetch='Openpose/concat_stage7' |  out: file --mode=REPLACE --directory='/output/pose-estimation' --binary=true --name-expression='headers[file_name]'
----

=== Twitter Sentiment Analysis

The https://github.com/spring-cloud-stream-app-starters/tensorflow/tree/master/spring-cloud-starter-stream-processor-twitter-sentiment[Twitter Sentiment Analysis processor] evaluates tweet messages into `POSITIVE`, `NEGATIVE` and `NEUTRAL`
categories. Output is encoded as JSON message

[source,bash]
----
tweets=twitterstream --access-token-secret=<Add Yours> --access-token=<Add Yours> --consumer-secret=<Add Yours> --consumer-key=<Add Yours> --track=java --stream-type=filter | filter --expression=#jsonPath(payload,'$.lang')=='en' | twitter-sentiment --vocabulary='http://dl.bintray.com/big-data/generic/vocab.csv' --output-name='output/Softmax' --model-fetch='output/Softmax' --model='http://dl.bintray.com/big-data/generic/minimal_graph.proto' | log
----

